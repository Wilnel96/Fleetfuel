import dotenv from 'dotenv';
dotenv.config();

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

async function executePostgresSQL(sql) {
  // Use PostgREST to execute raw SQL
  const response = await fetch(`${supabaseUrl}/rest/v1/rpc/exec`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'apikey': supabaseServiceKey,
      'Authorization': `Bearer ${supabaseServiceKey}`,
      'Prefer': 'params=single-object'
    },
    body: JSON.stringify(sql)
  });

  return { ok: response.ok, status: response.status };
}

async function getCount() {
  const response = await fetch(`${supabaseUrl}/rest/v1/garages?select=id`, {
    method: 'HEAD',
    headers: {
      'apikey': supabaseServiceKey,
      'Authorization': `Bearer ${supabaseServiceKey}`,
      'Prefer': 'count=exact'
    }
  });

  const range = response.headers.get('content-range');
  if (range) {
    const match = range.match(/\/(\d+)$/);
    return match ? parseInt(match[1]) : 0;
  }
  return 0;
}

async function importGarages() {
  console.log('ğŸš€ Starting garage import...\n');

  try {
    const beforeCount = await getCount();
    console.log(`ğŸ“Š Current garage count: ${beforeCount}\n`);

    const sqlFile = path.join(__dirname, 'combined_batches_01-10.sql');

    if (!fs.existsSync(sqlFile)) {
      console.error(`âŒ File not found: ${sqlFile}`);
      process.exit(1);
    }

    console.log(`ğŸ“– Reading ${path.basename(sqlFile)}...`);
    const sqlContent = fs.readFileSync(sqlFile, 'utf8');

    // Count INSERT statements
    const insertCount = (sqlContent.match(/INSERT INTO garages/g) || []).length;
    console.log(`âœ… Found ${insertCount} INSERT statements\n`);

    // Read all chunk files
    const chunkFiles = fs.readdirSync(__dirname)
      .filter(f => f.startsWith('batch_chunk_'))
      .sort();

    console.log(`ğŸ“¦ Processing ${chunkFiles.length} chunks...\n`);

    let processed = 0;
    let succeeded = 0;

    for (const chunkFile of chunkFiles) {
      const chunkPath = path.join(__dirname, chunkFile);
      const chunkSQL = fs.readFileSync(chunkPath, 'utf8').trim();

      if (chunkSQL.length === 0) continue;

      try {
        // Try to execute the chunk
        const result = await executePostgresSQL(chunkSQL);

        // Count as success if OK or conflict (409)
        if (result.ok || result.status === 409) {
          succeeded++;
        }
      } catch (err) {
        // Ignore errors due to ON CONFLICT DO NOTHING
      }

      processed++;
      const progress = Math.round((processed / chunkFiles.length) * 100);
      process.stdout.write(`\rğŸ“ˆ Progress: ${processed}/${chunkFiles.length} chunks (${progress}%)`);

      // Small delay to avoid rate limiting
      await new Promise(resolve => setTimeout(resolve, 50));
    }

    console.log('\n\n' + '='.repeat(60));
    console.log('âœ¨ IMPORT COMPLETE');
    console.log('='.repeat(60));
    console.log(`ğŸ“¦ Chunks processed: ${processed}`);
    console.log(`âœ… Successful: ${succeeded}`);

    const afterCount = await getCount();
    console.log(`\nğŸ“Š Garage count before: ${beforeCount}`);
    console.log(`ğŸ“Š Garage count after: ${afterCount}`);
    console.log(`ğŸ†• New garages added: ${afterCount - beforeCount}`);

    // Clean up chunk files
    console.log('\nğŸ§¹ Cleaning up temporary files...');
    chunkFiles.forEach(f => {
      try {
        fs.unlinkSync(path.join(__dirname, f));
      } catch (e) {
        // Ignore
      }
    });

    console.log('\nğŸ‰ Import completed successfully!');

  } catch (error) {
    console.error('\nâŒ Error:', error.message);
    process.exit(1);
  }
}

importGarages();
